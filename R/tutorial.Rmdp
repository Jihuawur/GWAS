---
title: "Supplementary web-based tutorial to 'A guide to genome-wide association analysis and post-analytic interrogation, Statistics in Medicine, in review.'"
author: "Eric Reed, et al"
date: "May 12, 2015"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, warning=FALSE)
```

This tutorial presents fundamental concepts and specific software tools for implementing a complete genome wide association (GWA) analysis, as well as post-analytic visualization and interrogation of potentially novel findings.  In this tutorial we use complete GWA data on 1401 individuals from the [PennCATH study of coronary artery disease (CAD)](http://link-here/).

In the steps to follow we begin by demonstrating a method for downloading necessary R packages and setting global parameters as a means for saving progress while working through a GWA analysis.  Next, we include quality control steps for both SNP and sample level filtering. The third section is split into principal component calculation for population stratification in statistical modelling, as well as imputation of non-typed SNPs using [1000 Genomes](http://www.1000genomes.org/) reference genotype data.  We then demonstrate strategies to carry out the GWA analysis on the typed data using basic linear modelling functionality in R, as well as imputed data using functionality contained within the [**snpStats**](http://www.bioconductor.org/packages/release/bioc/html/snpStats.html) package. Finally, we demonstrate means for post-analytic interrogation, including methods for evaluating the performance of statistical models, as well as visualization of the global and subsetted GWAS output.

## Installing necessary packages

This tutorial utlizes several packages available from [Bioconductor](http://www.bioconductor.org/), an open-soure bioinformatic software repository. Of these, we make the most use of [**snpStats**](http://www.bioconductor.org/packages/release/bioc/html/snpStats.html), which includes functions to read in various formats of genotype data, and carry out quality control, imputation and association analysis, as well as [**SNPRelate**](http://master.bioconductor.org/packages/release/bioc/html/SNPRelate.html), which include functions for sample level quality control, and computationally efficient principal component calculation. Other packages include funtionality for data visualization ([**rtracklayer**](http://www.bioconductor.org/packages/release/bioc/html/rtracklayer.html), [**LDheatmap**](http://cran.r-project.org/web/packages/LDheatmap/index.html), [**ggplot2**](http://ggplot2.org/)), data manipulation ([**plyr**](http://plyr.had.co.nz/), [**GenABEL**](http://www.genabel.org/packages/GenABEL)), and parallel processing ([**doParallel**](http://cran.r-project.org/web/packages/doParallel/index.html)).

```{r "code0.r"/code0, eval=FALSE}
```

## Configuring global parameters

We first attempt to isolate most of the variable parameters used in the data processing and analysis.  Of particular note, users should set the location of the GWA data set.  Other variables here specify input and output.

```{r "globals.R"/globals}
```

## Data pre-processing

For this tutorial we use genotype data files formatted for use with [PLINK](http://pngu.mgh.harvard.edu/~purcell/plink/) software.  We utilize the function, `read.plink`, from **snpStats**, which allows the reading in of data formatted as *.bed*, *.bim*, and *.fam* files.  The *.bed* file contains the genotype information, coded in binary.  The *.bim* file contains information for each SNP with a respective column for each of the following information: chromosome number, SNP name (typically an rs #), genetic distance (not necessary for this tutorial), chromosomal position, identity of allele 1, and identity of allele 2. The assignment of allele 1 and allele 2, pertains to the effect allele, or which allele is being counted when we assign a numeric value to a genotype. This is typically assigned based on allele frequency, though not always. In this tutorial allele 1 pertains to the minor, or less common, allele. Lastly, the *.fam* file contains information for each sample with a respective column for each of the following information: family ID (this will be used to identify each subject when read into R), individual ID, paternal ID, maternal ID, sex (coded as 1 = male and 2 = female), and phenotype (note: in this tutorial we utilize a supplemental clinical file for outcome variables and additional covariates).

Alternatively, similar genotype information can also be formatted for PLINK software as *.ped* and *map* files.  The information of the *.ped* file can be thought of as a combination of the *.bed*  and *.fam* files. It is a large table with the first six columns, identical to a *.fam* file, followed a column with the genotype data for each SNP. The *.map* file contains the first the first four columns of the *.bim* file, without the allele assignments.  These files can be read in using the function, `read.pedfile`,  from  **snpStats**.  


```{r "code1.r"/code1-a}
```

The `geno` object contains a `genotype` member of type `snpMatrix` where each column is a SNP and each row is a sample.  For convenience, we assign that to the object, `genotype`. Within this object individual genotypes are assigned in the `snpMatrix` specific `RAW` format. `geno` also contains the information from the *.bim* file within the `map` member that we assign to `genoBim`.

```{r "code1.r"/code1-b}
```

Supplemental clinical data is found in a corresponding CSV file for each sample. It contains a column for the subject ID (Family ID in the *.fam* file) and a respective column for each of the following variables: coronary artery disease status (coded as 0 = control and 1 = affected), sex (coded as 1 = male, 2 = female), age (years), triglyceride level (mg/dL), high-density lipoprotein level (mg/dL), low-density lipoprotein level (mg/dL).

```{r "code1.r"/code1-c}
```

We filter the genotype data to only include samples with corresponding clinical data by indexing the `SnpMatrix` using the sample IDs, which match the row names.

```{r "code1.r"/code1-d}
```

## SNP level filtering

Once the data is loaded, we are ready to remove SNPs that fail to meet
minimum criteria due to missing data, low variability or genotyping
errors.  **snpStats** provides `col.summary` and `row.summary` functions
that return statistics on SNPs and samples, respectively.

```{r "code2.r"/code2-a}
```

Using these summary statistics, we keep the subset of SNPs that our criteria for minimum call rate and minor allele frequency.

```{r "code2.r"/code2-b}
```

## Sample level filtering

The second stage of data pre-processing involves filtering samples,
i.e. removing individuals due to missing data, sample contamination,
correlation (for population-based investigations) and racial/ethnic or
gender ambiguity or discordance.  In our study, we address these
issues by filtering on call rate, heterozygosity, cryptic relatednes
and duplicates using identity-by-descent, and we visually assess
ancestry.

### Basic sample filtering

Sample level quality control for missing data and heterozygosity is achieved using the `row.summary` function from **snpStats**.  An additional heterozygosity F statistic calculation is carried out with the form, $|F|=(1-O/E)$, where $O$ is observed proportion of heterozygous genotypes for a given sample and $E$ is the expected proportion of heterozygous genotypes for a given sample based on the minor allele frequency accross all non-missing SNPs for a given sample. 

```{r "code3.r"/code3-a, cache.lazy=FALSE, cache.vars='snpsum.row'}
```

We apply filtering on call rate and heterozygosity, selecting only 
those samples that meet our criteria.

```{r "code3.r"/code3-b}
```

### IBD analysis

In addition to these summary statistics, we also want to filter on
relateness criteria.  We use the **SNPRelate** package to perform
identity-by-descent (IBD) analysis.  This package requires that the
data be transformed into a *GDS* format file.  IBD analysis is
performed on only a subset of SNPs that are in linkage equilibrium by
iteratively removing adjacent SNPs that exceed an LD threshold in a
sliding window (function `snpgdsLDpruning`).

```{r "code3.r"/code3-c}
```

The `snpgdsIBDMoM` function computes the IBD coefficients using method
of moments.  The result is a table indicating kinship among pairs of
samples.

```{r "code3.r"/code3-d}
```

Using the IBD pairwise sample relatedness measure, we iteratively
remove samples that are too similar using a greedy strategy in which
the sample with the largest number of related samples is removed.  The
process is repeated until there are no more pairs of samples with
kinship coefficients above our cut-off.

```{r "code3.r"/code3-e}
```

### Ancestry

To better understand ancestry, we plot the first two principal
components of the genotype data.  It is important to note that this example we are reasonably confident that our samples are homogeneous, coming from european ancestry. Therefore, given that there are no clear outliers we fail to remove any samples. 

```{r "code3.r"/code3-f, fig.align='center'}
```

## SNP Filtering - HWE filtering on control samples

Finally, once samples are filtered, we return to SNP level filtering
and apply a check of Hardy-Weinberg equilibrium for just the study controlsand remove those that exceed our cut-off.

```{r "code3.r"/code3-g}
```

## Re-compute PCA

With our final set of filtered SNPs and samples, we recompute the
principal components again to be used in later model fitting.

```{r "code4.r"/code4-a}
```


## Imputation of SNPs

In addition to the genotyped SNPs from our study, it is useful to
extend the analysis to other known SNPs in our region of interest
(chromsome 16).  We retrieve additional SNPs by reading a PED file
from the 1000 Genomes project.  Then we derive imputation "rules" for
the additional SNPs that were not typed in our study using
`snp.imputation` based on the haplotypes from the 1000 Genomes data.
Each rule is a model for the distribution of the genotypes for each
SNP based on the typed SNPs.  Using these rules, we impute the
genotypes of the additional SNPs for the samples in our study.

```{r "code5.r"/code5-a}
```

## Genome-wide association analysis

Now that our data is loaded, filtered, and additional SNP genotypes
imputed, we are ready to perform genome-wide association analysis.
This involves regressing each SNP separately on a given trait,
adjusted for patient level clinical, demographic and environmental
factors.  Due to the large number of SNPs and the generally
uncharacterized relationships to the outcome, a simple single additive
model will be employed.  A Bonferonni corrected significant threshold
of $5 x 10^-8$ is used to control for family-wide error rate.

Due to the large number of models that require fitting, the GWA
analysis can be deployed in parallel across multiple processors or
machines to reduce the running time.  Here we demonstrate two basic
methods for performing parallel processing using the *doParallel*.
These approaches are demonstrated in the function GWAA:

### GWAA function

```{r "GWAA.R"/gwaa}
```

### Phenotype data preparation

First we create a data.frame of phenotype features that is the
concatenation of clinical features and the first ten principal
components.  The HDL feature is normalized using a rank-based inverse
normal transform.

```{r "code6.r"/code6-a}
```

### Parallel model fitting

Using this phenotype data, we perform model fitting on each of the
SNPs genotyped in the study and write the results to a CSV file.

```{r "code6.r"/code6-b}
```

### Model fitting of non-typed SNPs using rules

We also perform association testing on the additional SNPs from the
1000 Genomes project.  Instead of using a single imputed genotype
value, we use the "rules" derived from the haplotype analysis, above.
The resulting SNPs are combined with the chromosome position
information to create a table of SNPs, location and score.

```{r "code7.r"/code7-a}
```

### Mapping associated SNPs to genes

Using a separate data file containing the chromosome and coordinate
locations of each protein coding gene, we can locate coincident genes
and SNPs with significant association p-values.

We use the following function to extract the subset of SNPs that are
near our gene of interest:

```{r "map2gene.R"/map2gene}
```

And then we call the map2gene function for "CETP" and then filter the
imputed genotypes to extract only those SNPs that are near CETP.

```{r "code7.r"/code7-b}
```

## Post-analytic visualization and genomic integration

We now have generated and fit both typed and imputed genotypes.  The
next step is to combine the results, and isolate just those SNPs in
our region of interest.  Following similar steps as above for imputed
steps, the typed SNPs are loaded from a file generated by the `GWAA`
function and then we follow similar steps to attach chromosome and
position to each SNP, order by significance.

```{r "code8.r"/code8-a}
```

### Isolate CETP-specific SNPs

The two tables of typed and imputed genotypes are combined into a
single table.  In addition, we also concatenate just the SNPs near
CETP and display them all here.

```{r "code8.r"/code8-b}
```

## Visualization and QC ##

Several plots allow us both to visualize the GWA analysis findings
while performing quality control checks.  Specifically, we are
interested in identifying data inconsistencies, potential systemic
biases and redundancies of our findings with previously reported
results.

### Manhattan plot ###

Manhattan plots are used to visual GWA significant results by
chromosome location.  We will use this function to plot a set of
SNPs across the genome.

```{r "GWAS_ManhattanFunction.R"/manhattan}
```

```{r "code9.r"/code9-a}
```

### Quantile-quantile plots and the $\lambda$-statistic ### 

Q-Q plots are used to visualize the relationship between the expected
and observed distributions of SNP level test statistics.  Here we
compare these statistics for the unadjusted model (left) compared with
the model adjusted for confounders by incorporating the first ten
principal compoents along with sex, age and CAD.

A new set of models is generated with only the phenotype (HDL) and no
additional factors.  The results are plotted using the `GenABEL`
package's `estlambda` function.

```{r "code9.r"/code9-b}
```

We see here that the tail of the distribution is brough closer to the
y=x line after accounting for confounding by race/ethnicity in the
modeling framework.  If the data in this figure were shifted up or
down from the $y=x$ line, then we would want to investigate some form
of systemic bias.  The degree of deviation from this line is measured
formally by the $\lambda$-statistic, where a value close to 1 suggests
appropriate adjustment for the potential admixture.  A slight
deviation in the upper right tail from the $y=x$ line suggests crudely
that some form of association is present in the data.  There is only a
slight improvement in $\lambda$ between the unadjusted model and the
model with PCs indicating that the population is relatively
homogenous.

### Heatmap ###

Heatmaps are typically used in the context of GWA analysis to
visualize the linkage disequilibrium pattern between significant SNPs
other SNPs in nearby regions.  Here we include our most significant
SNP from our analysis and other SNPs near CETP.  The darker shading
indicates higher LD.  The plot also includes $-log_{10}(p)$ values to
illustrate their connection with physical location.

```{r "code9.r"/code9-c}
```

